Aqui est√° o seu **README.md** atualizado.

Fiz altera√ß√µes importantes na **Se√ß√£o 6 (Sticky Sessions)**. Substitu√≠ o exemplo antigo pela configura√ß√£o que funcionou (usando Gateway) e adicionei a explica√ß√£o t√©cnica de **POR QUE** precisamos usar o Gateway e n√£o o Service direto, al√©m de corrigir o nome do campo para `httpCookie`.

---

# üìÑ README.md

```markdown
# Guia de Implementa√ß√£o: Canary Deployment com Nginx e Kubernetes

Este guia detalha o processo de cria√ß√£o de duas vers√µes de uma aplica√ß√£o Nginx, o envio para o Docker Hub e o deploy em um cluster Kubernetes com balanceamento de carga e controle fino via Istio.

## üõ†Ô∏è 1. Prepara√ß√£o das Imagens Docker

Precisamos criar dois contextos diferentes para que cada imagem exiba uma mensagem √∫nica.

### Vers√£o A (Latest)
1. Crie uma pasta chamada `app-a` e um arquivo `Dockerfile` dentro dela:
```dockerfile
FROM nginx:alpine
RUN echo "ACESSOU TESTE A" > /usr/share/nginx/html/index.html
```

2. Build da imagem:
```bash
docker build -t pedrovieira249/nginx-ab:latest ./app-a
```

### Vers√£o B
1. Crie uma pasta chamada `app-b` e um arquivo `Dockerfile` dentro dela:
```dockerfile
FROM nginx:alpine
RUN echo "ACESSOU TESTE B" > /usr/share/nginx/html/index.html
```

2. Build da imagem:
```bash
docker build -t pedrovieira249/nginx-ab:b ./app-b
```

---

## üß™ 2. Teste Local (Opcional, mas Recomendado)

Antes de subir para o registro, valide se as imagens est√£o respondendo corretamente:

```bash
# Testar A
docker run -d -p 8081:80 --name t-a pedrovieira249/nginx-ab:latest
curl localhost:8081 # Deve retornar: ACESSOU TESTE A
docker rm -f t-a

# Testar B
docker run -d -p 8082:80 --name t-b pedrovieira249/nginx-ab:b
curl localhost:8082 # Deve retornar: ACESSOU TESTE B
docker rm -f t-b
```

---

## üöÄ 3. Upload para o Docker Hub

Fa√ßa o login e envie as imagens para o seu reposit√≥rio remoto:

```bash
docker login
docker push pedrovieira249/nginx-ab:latest
docker push pedrovieira249/nginx-ab:b
```

---

## ‚ò∏Ô∏è 4. Deploy no Kubernetes

Com as imagens dispon√≠veis, aplique o manifesto `deployment.yaml` que cont√©m os dois Deployments (`nginx` e `nginx-b`) e o Service compartilhado.

```bash
kubectl apply -f deployment.yaml
```

Verifique se os 4 pods (2 de cada vers√£o) est√£o rodando:
```bash
kubectl get pods -l app=nginx
```

---

## üö¶ 5. Controle de Tr√°fego com Istio (Canary Release - Pesos)

O Istio permite definir pesos espec√≠ficos para cada vers√£o.

### 1. Aplicar as Regras de Tr√°fego (Peso 60/40)
Rode os comandos abaixo para configurar a divis√£o de tr√°fego:

```bash
kubectl apply -f ./destination-rule.yaml
kubectl apply -f ./virtual-service.yaml
```

> **‚ö†Ô∏è Nota:** Ao usar pesos, o Istio faz um balanceamento probabil√≠stico. Um mesmo usu√°rio pode ver a vers√£o A e depois a B.

---

## üç™ 6. Sticky Sessions (Sess√µes Persistentes via Cookie)

Para garantir que um usu√°rio fique "preso" a uma vers√£o espec√≠fica (ex: Client-A sempre cai no Pod A), precisamos usar **Consistent Hash**.

### 1. Configura√ß√£o Correta (`consistent-hash.yaml`)
Aplique o arquivo abaixo. Note que adicionamos um **Gateway** e removemos os pesos.

```bash
kubectl apply -f consistent-hash.yaml
```

**Conte√∫do do arquivo explicado:**
```yaml
apiVersion: networking.istio.io/v1
kind: Gateway
metadata:
  name: nginx-gateway
spec:
  selector:
    istio: ingressgateway # Usa o Ingress Controller do Istio
  servers:
  - port: { number: 80, name: http, protocol: HTTP }
    hosts: ["*"]
---
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: nginx-virtual-service
spec:
  hosts: ["*"]
  gateways: ["nginx-gateway"] # OBRIGAT√ìRIO: Liga ao Gateway
  http:
  - route:
    - destination:
        host: nginx-service
        # SEM PESOS (weights) AQUI! 
        # Deixamos o DestinationRule decidir qual pod usar baseado no hash.
---
apiVersion: networking.istio.io/v1
kind: DestinationRule
metadata:
  name: nginx-destination-rule
spec:
  host: nginx-service
  trafficPolicy:
    loadBalancer:
      consistentHash:
        httpCookie:          # Usa cookie HTTP para o hash
          name: "user-session"
          ttl: 60s
```

### 2. Por que esta configura√ß√£o √© necess√°ria?

1.  **Gateway vs Service:** O Sticky Session **N√ÉO** funciona se voc√™ acessar via `localhost:8000` (Service do K8s). O Service do Kubernetes faz apenas balanceamento TCP (Round Robin). Para o Istio ler o cookie e decidir o destino, o tr√°fego **tem que passar pelo Istio Ingress Gateway**.
2.  **Sem Pesos (Weights):** No `VirtualService`, removemos a divis√£o de porcentagem. Se defin√≠ssemos pesos, o Istio escolheria aleatoriamente a vers√£o ANTES de verificar o cookie. Sem pesos, ele delega a escolha totalmente para o algoritmo de Hash do `DestinationRule`.
3.  **httpCookie:** A sintaxe correta na API moderna do Istio √© `httpCookie`, e n√£o apenas `cookie`.

### 3. Como testar (Port-Forward no Gateway)

N√£o acesse o servi√ßo diretamente. Acesse o **Gateway**:

1.  Fa√ßa o port-forward do Ingress Gateway em um terminal separado:
    ```bash
    # A porta do Gateway geralmente √© a 80 interna, mapeamos para 8080 local
    kubectl port-forward -n istio-system svc/istio-ingressgateway 8080:80
    ```

2.  Teste a persist√™ncia:
    ```bash
    # O usu√°rio "client-A" ser√° hashado sempre para o mesmo pod
    while true; do curl -b "user-session=client-A" http://localhost:8080; sleep 0.5; done
    
    # O usu√°rio "client-B" ser√° hashado para outro pod (e ficar√° l√°)
    while true; do curl -b "user-session=client-B" http://localhost:8080; sleep 0.5; done
    ```
    OBS: Pode ser que ao rodar o primeiro comando, o Istio ainda n√£o tenha criado o cookie. Aguarde alguns segundos para que o cookie seja criado e a persist√™ncia funcione corretamente. E mesmo rodando com o user-session=client-A o cliente pode ser mandado para o outro pod na primeira requisi√ß√£o, mas nas pr√≥ximas ele sempre cair√° no mesmo pod.
---

## üîç 7. Monitoramento com Kiali

1. Dispare carga com o Fortio (ferramenta de teste de carga):
```bash
kubectl exec [NOME_DO_POD_FORTIO] -c fortio -- fortio load -c 2 -qps 0 -t 200s -loglevel Warning http://nginx-service:8000
```

2. Acesse o dashboard do Kiali e v√° em **Graph**.
3. Selecione o namespace e ative **Traffic Distribution**. Voc√™ ver√° visualmente como o tr√°fego est√° sendo distribu√≠do.

---

## üßπ 8. Limpeza do Ambiente

```bash
k3d cluster delete
```
```